---
title: "Regression"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: journal
    code_folding: "hide"
---
<br>

<font size="4" color="black">

1) We first loaded the necessary packages to start on building regression models and the cleaned rat dataset 

```{r, message = FALSE}
library(tidyverse)
library(lubridate)
library(readr) 
library("ggplot2") 
library("dplyr")
library(xts)
library("lubridate")
library("RColorBrewer")
library("ggthemes")
library("gridExtra")
library("leaflet")
library("highcharter")
library(scales)
library(leaflet.extras)
library(modelr)
library(broom)

rats_raw <- read.csv("./Rat_Sightings.csv", na = c("", "NA", "N/A", "Unspecified")) %>%
  janitor::clean_names() %>% 
  mutate(created_date = mdy_hms(created_date)) %>%
  mutate(sighting_year = year(created_date),
         sighting_month_num = month(created_date),
         sighting_month = month(created_date, label = TRUE, abbr = FALSE),
         sighting_day = day(created_date),
         sighting_weekday = wday(created_date, label = TRUE, abbr = FALSE)) %>%
  mutate(season = case_when(
    sighting_month_num %in% c("12", "1", "2") ~ "Winter",
    sighting_month_num %in% c("3", "4", "5") ~ "Spring",
    sighting_month_num %in% c("6", "7", "8") ~ "Summer",
    sighting_month_num %in% c("9", "10", "11") ~ "Fall",
    TRUE ~ "Unknown"  # Catch-all for unexpected values
  )) %>%
  mutate(season = as.factor(season))

```

2) In order to assess whether `location_type`, `sighting_year`, `borough` and `season` are significant predictors of rats per month (`rat_per_month`), we utilized a stepwise selection algorithm. We used `stepAIC` command from the `MASS` package to perform a stepwise model selection by optimizing AIC. 

```{r}
rat_stepwise <-
rats_raw %>%
  filter(location_type %in% c("3+ Family Apt. Building", "1-2 Family Dwelling", "3+ Family Mixed Use Building", "Commercial Building", "Vacant Lot", "Construction Site")) %>%
  group_by(location_type, sighting_month_num, sighting_year, borough, season) %>%
  mutate(rat_per_month = n()) %>%
  slice(1) %>%
  select(location_type, sighting_month_num, sighting_year, borough, rat_per_month, season) %>% 
  mutate(sighting_month_num = as.numeric(sighting_month_num))

```

```{r}
model_step = lm(rat_per_month ~ location_type + sighting_year + borough + season, data = rat_stepwise)
stepcount <- MASS::stepAIC(model_step, direction = "both", trace = FALSE) %>% broom::tidy()
knitr::kable(stepcount, digits = 3)
```

2) We found 4 variables that we thought would be useful in predicting the number of rats per month: `location_type`, `sighting_year`, `borough` and `season`. 

```{r, results= FALSE}
rat_location <-
rats_raw %>%
  filter(location_type %in% c("3+ Family Apt. Building", "1-2 Family Dwelling", "3+ Family Mixed Use Building", "Commercial Building", "Vacant Lot", "Construction Site")) %>%
  group_by(location_type, borough , sighting_year, season) %>%
  mutate(rat_per_month = n()) %>%
  slice(1) %>%
  select(location_type, borough, sighting_year, rat_per_month, season) 
```

3) We built a model that predicts rats per month (`rat_per_month`) from `location_type`, `sighting_month_num`, `sighting_year`, and `season`. 

```{r}
model <- lm(rat_per_month ~ sighting_year + borough + location_type + season, data = rat_location)
summary(model)
```

4) We then ran a k-fold cross-validation technique to create training and testing data sets and ran a new linear regression model for each of the training sets.

```{r, results = FALSE}
set.seed(23) 
rats_folds <- crossv_kfold(rat_location, k = 10)
rats_folds <- rats_folds %>% mutate(model = map(train, ~ lm(rat_per_month ~ ., data = .)))
```

5) We generated predictions using the models fitted during k-fold cross-validation. 

```{r, results = FALSE}
prediction <- 
  rats_folds %>%
  mutate(predicted = map2(model, train, ~ augment(.x, newdata = .y))) %>% 
  unnest(predicted)
```

6) We created a residual plot to visually assess the performance of our model.

```{r, warning = FALSE}
prediction <- prediction %>% 
  mutate(residual = .fitted - rat_per_month)

prediction%>%
  ggplot(aes(rat_per_month, residual)) +
    geom_hline(yintercept = 0) +
    geom_point() +
    stat_smooth(method = "loess") +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 500))
```

We then produced linear regression prediction a second time, but instead to predict the number of rats per month based off the analysis that we conducted earlier in the report. Reviewing the graph of rat_per_month vs. the residual data, we see that the data points are more evenly spread out and the regression line is better fit to the data. The variables chosen were not heavily correlated with each other giving us a more accurate representation of the actual data. We found an adjusted R^2 value of 0.5838. This lower R^2 value means that less of the variability is explained by the model, but it is a more realistic depiction of our dataset. 
